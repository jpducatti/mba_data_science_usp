{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# MBA em Ciência de Dados - Análise de Dados com Base em Processamento Massivo em Paralelo ##\n","\n","### Aula 06: Processamento Paralelo e Distribuído\n","\n","## Lista de Exercícios com Respostas ##"],"metadata":{"id":"WLISLDOkYs9q"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"qpVtHzdJYvZ5"}},{"cell_type":"markdown","metadata":{"id":"2QbaUWeQxHYR"},"source":["**Material Produzido por:**<br>\n",">**Profa. Dra. Cristina Dutra de Aguiar**<br>\n","\n","**CEMEAI - ICMC/USP São Carlos**\n","\n","Esta lista possui 11 exercícios, sendo possível navegar pelos mesmos utilizando o sumário na esquerda. Os primeiros exercícios contam com dicas para auxiliar na sua resolução. Leiam-os com atenção e desenvolvam as respostas nos blocos indicados com \n","```\n","# Resposta do exercício\n","```\n","\n","Por completude, o *notebook* possui todas as descrições apresentadas na parte prática da Aula 06. **Recomenda-se fortemente** que esta lista seja respondida antes de se consultar o material com as respostas.\n"]},{"cell_type":"markdown","metadata":{"id":"AWKkx5f8xTMM"},"source":["# 1 Introdução\n","\n","A aplicação de *data warehousing* da BI Solutions utiliza como base uma contelação de fatos que une dois esquemas estrela, conforme descrito a seguir.\n","\n","**Tabelas de dimensão**\n","\n","- data (`dataPK, dataCompleta, dataDia, dataMes, dataBimestre, dataTrimestre, dataSemestre, dataAno`)\n","- funcionario (`funcPK, funcMatricula, funcNome, funcSexo, funcDataNascimento, funcDiaNascimento, funcMesNascimento, funcAnoNascimento, funcCidade, funcEstadoNome, funcEstadoSigla, funcRegiaoNome, funcRegiaoSigla, funcPaisNome, funcPaisSigla`)\n","- equipe (`equipePK, equipeNome, filialNome, filialCidade, filialEstadoNome, filialEstadoSigla, filialRegiaoNome, filialRegiaoSigla, filialPaisNome, filialPaisSigla`)\n","- cargo (`cargoPK, cargoNome, cargoRegimeTrabalho, cargoEscolaridadeMinima, cargoNivel`)\n","- cliente (`clientePK, clienteNomeFantasia, clienteSetor, clienteCidade, clienteEstadoNome, clienteEstadoSigla, clienteRegiaoNome, clienteRegiaoSigla, clientePaisNome, clientePaisSigla`)\n","\n","**Tabelas de fatos**\n","- pagamento (`dataPK, funcPK, equipePK, cargoPK, salario, quantidadeLancamento`)\n","- negociacao (`dataPK, equipePK, clientePK, receita, quantidadeNegociacao`)"]},{"cell_type":"markdown","metadata":{"id":"vYmvShw4vfP5"},"source":["Primeiramente, são definidos `paths`, sendo que cada `path` se refere a uma tabela de fatos ou uma tabela de dimensão. "]},{"cell_type":"code","metadata":{"id":"G1kwE479vk4N"},"source":["# Tabelas de dimensão\n","pathData = 'dados/data.csv'\n","pathFuncionario = 'dados/funcionario.csv'\n","pathEquipe = 'dados/equipe.csv'\n","pathCargo = 'dados/cargo.csv'\n","pathCliente = 'dados/cliente.csv'\n","\n","# Tabelas de fato\n","pathPagamento = 'dados/pagamento.csv'\n","pathNegociacao = 'dados/negociacao.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hiIhXOKe11No"},"source":["Na sequência,  todos os arquivos referentes às tabelas de fatos e às tabelas de dimensão são baixados, sendo armazenados na pasta `dados`."]},{"cell_type":"code","metadata":{"id":"kHsUKNlvvaBT"},"source":["%%capture\n","!git clone https://github.com/GuiMuzziUSP/Data_Mart_BI_Solutions.git dados"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qlYaf6zo0W_B"},"source":["# 2 Apache Spark Cluster: instalação e configuração"]},{"cell_type":"markdown","metadata":{"id":"5Zl1gR_qy1PD"},"source":["**2.1 Instalação**\n","\n","Neste *notebook* é criado um *cluster* Spark composto apenas por um **nó mestre**. Ou seja, o *cluster* não possui um ou mais **nós de trabalho** e o **gerenciador de cluster**. Nessa configuração, as tarefas (*tasks*) são realizadas no próprio *driver* localizado no **nó mestre**."]},{"cell_type":"code","metadata":{"id":"vjO0nAeqyRna"},"source":["#instalando Java Runtime Environment (JRE) versão 8\n","%%capture\n","!apt-get remove openjdk*\n","!apt-get update --fix-missing\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FDL6HLRhzHzL"},"source":["Na sequência, é feito o *download* do Apache Spark versão 3.0.0."]},{"cell_type":"code","metadata":{"id":"5ItvOmwstGOO"},"source":["#baixando Apache Spark versão 3.0.0\n","%%capture\n","!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n","!tar xf spark-3.0.0-bin-hadoop2.7.tgz && rm spark-3.0.0-bin-hadoop2.7.tgz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hcPvn_vgtJ6l"},"source":["Na sequência, são configuradas as variáveis de ambiente JAVA_HOME e SPARK_HOME. Isto permite que tanto o Java quanto o Spark possam ser encontrados."]},{"cell_type":"code","metadata":{"id":"HAXvU63xtRck"},"source":["import os\n","#configurando a variável de ambiente JAVA_HOME\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","#configurando a variável de ambiente SPARK_HOME\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n8hAOJtBtY7M"},"source":["Por fim, são instalados dois pacotes da linguagem de programação Python, cujas funcionalidades são descritas a seguir.\n","\n","Pacote findspark: Usado para ler a variável de ambiente SPARK_HOME e armazenar seu valor na variável dinâmica de ambiente PYTHONPATH. Como resultado, Python pode encontrar a instalação do Spark.\n","\n","Pacote pyspark: PySpark é a API do Python para Spark. Ela possibilita o uso de Python, considerando que o framework Apache Spark encontra-se desenvolvido na linguagem de programação Scala."]},{"cell_type":"code","metadata":{"id":"X-0U9STdtZ4Y"},"source":["%%capture\n","#instalando o pacote findspark\n","!pip install -q findspark==1.4.2\n","#instalando o pacote pyspark\n","!pip install -q pyspark==3.0.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1xrBLEKI0OWx"},"source":["**2.2 Conexão**\n","\n","PySpark não é adicionado ao *sys.path* por padrão. Isso significa que não é possível importá-lo, pois o interpretador da linguagem Python não sabe onde encontrá-lo. \n","\n","Para resolver esse aspecto, é necessário instalar o módulo `findspark`. Esse módulo mostra onde PySpark está localizado. Os comandos a seguir têm essa finalidade."]},{"cell_type":"code","metadata":{"id":"0RAqybyZYKdn"},"source":["#importando o módulo findspark\n","import findspark\n","#carregando a variávels SPARK_HOME na variável dinâmica PYTHONPATH\n","findspark.init()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bJjl5aEvtnur"},"source":["Depois de configurados os pacotes e módulos e inicializadas as variáveis de ambiente, é possível criar o objeto SparkContext. No comando de criação a seguir, é definido que é utilizado o próprio sistema operacional deste notebook como nó mestre por meio do parâmetro local do método setMaster. O complemento do parametro [*] indica que são alocados todos os núcleos de processamento disponíveis para o objeto driver criado."]},{"cell_type":"code","metadata":{"id":"KB7ZlgxIVss3"},"source":["from pyspark import SparkConf, SparkContext\n","\n","conf = SparkConf().setMaster(\"local[*]\")\n","spark = SparkContext(conf=conf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c7SWE09n1sug"},"source":["# 3 Carregamento dos Dados da Aplicação da BI Solutions"]},{"cell_type":"markdown","metadata":{"id":"G8D5I5Fb5YrL"},"source":["**3.1 Carregamento da tabela de dimensão** *data*"]},{"cell_type":"markdown","metadata":{"id":"QPli-rPKjCMh"},"source":["O comando a seguir utiliza o método `textFile()` para armazenar no RDD chamado `data` os registros do arquivo de texto `\"data.csv\"`, os quais possuem os dados da tabela de dimensão `data`."]},{"cell_type":"code","metadata":{"id":"iWOM5WsQf2pa"},"source":["data_rdd = spark.textFile(pathData)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2076gqycn_yS"},"source":["Os comandos a seguir realizam alterações no RDD `data` de forma que seus elementos representem linhas (ou tuplas) da tabela."]},{"cell_type":"code","metadata":{"id":"FGN8-kownl0e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666900999771,"user_tz":180,"elapsed":1699,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"da94bb21-f050-46ca-ebc8-643c4a963a89"},"source":["#imprimindo as 3 primeiras linhas de \"data\" e verificando que a primeira linha contém metadados (ou seja, o esquema referente aos dados)\n","data_rdd.take(3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['dataPK,dataCompleta,dataDia,dataMes,dataBimestre,dataTrimestre,dataSemestre,dataAno',\n"," '1,1/1/2016,1,1,1,1,1,2016',\n"," '2,2/1/2016,2,1,1,1,1,2016']"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"mjJZjQySf2ho"},"source":["#removendo a primeira linha de \"data\", desde que ela se refere a metadados\n","#capturando o cabeçalho\n","firstRow = data_rdd.first()\n","#removendo o cabeçalho\n","data_rdd = data_rdd.filter(lambda line: line != firstRow)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cAFiGv_qycSu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666900999771,"user_tz":180,"elapsed":8,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"0b52ad73-0699-4e9e-9271-faa0ff20c66e"},"source":["#imprimindo as 3 primeiras linhas de \"data\" e verificando que elas contêm apenas dados\n","data_rdd.take(3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['1,1/1/2016,1,1,1,1,1,2016',\n"," '2,2/1/2016,2,1,1,1,1,2016',\n"," '3,3/1/2016,3,1,1,1,1,2016']"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"qvUk1tNTnCbO","colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"status":"ok","timestamp":1666900999772,"user_tz":180,"elapsed":8,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"850d4923-b6f6-44b4-e4f5-853204b1228d"},"source":["#imprimindo o cabeçalho de \"data\" e verificando os metadados \n","data_header = firstRow[:].split(\",\")\n","display(data_header)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["['dataPK',\n"," 'dataCompleta',\n"," 'dataDia',\n"," 'dataMes',\n"," 'dataBimestre',\n"," 'dataTrimestre',\n"," 'dataSemestre',\n"," 'dataAno']"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Rm57ZD8bhE6G"},"source":["Desde que o arquivo lido encontra-se no formato `.csv`, utiliza-se o método `()` para transformar os elementos do RDD `data` em uma lista de valores divididos por `\",\"`."]},{"cell_type":"code","metadata":{"id":"yMt3gxSLf2d7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666900999772,"user_tz":180,"elapsed":7,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"975c0dba-a53f-4c2d-891e-8f728e1865b8"},"source":["#mapeando os valores do RDD \"data\" utilizando o separador vírgula\n","data_rdd = data_rdd.map(lambda line: tuple(line.split(\",\")))\n","#imprimindo as 3 primeiras linhas de \"data\"\n","data_rdd.take(3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('1', '1/1/2016', '1', '1', '1', '1', '1', '2016'),\n"," ('2', '2/1/2016', '2', '1', '1', '1', '1', '2016'),\n"," ('3', '3/1/2016', '3', '1', '1', '1', '1', '2016')]"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"bCFWrvu8hSNx"},"source":["# **Exercícios**"]},{"cell_type":"markdown","metadata":{"id":"NzmenlB1etNP"},"source":["#### **Exercício 1**\n","\n","Dê continuidade ao exemplo anterior e realize o carregamento dos demais arquivos referentes à constelação de fatos da BI solution, a saber: (i) tabelas de dimensão `funcionario`, `equipe`, `cargo` e `cliente`; e (ii) tabelas de fato `pagamento` e `negociação`."]},{"cell_type":"code","metadata":{"id":"6xI-CWu6U1OO","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1666901000423,"user_tz":180,"elapsed":656,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"74e51c10-5b21-4d26-dc73-9c4e138d27c1"},"source":["# Resposta do exercício\n","\n","def processaRdd(spark, path):\n","  rddCsv = spark.textFile(path)\n","  #capturando o cabeçalho\n","  firstRow = rddCsv.first()\n","  rddCsv = rddCsv.filter(lambda line: line != firstRow)\n","  header = firstRow[:].split(\",\")\n","\n","  #processando o rddCsv\n","  rddCsv = rddCsv.map(lambda x: tuple(x.split(\",\")))\n","\n","  return header, rddCsv\n","\n","\n","#realizando o carregamento das tabelas de dimensão\n","funcionario_header, funcionario_rdd = processaRdd(spark, pathFuncionario)\n","equipe_header, equipe_rdd = processaRdd(spark, pathEquipe)\n","cargo_header, cargo_rdd = processaRdd(spark, pathCargo)\n","cliente_header, cliente_rdd = processaRdd(spark, pathCliente)\n","\n","#realizando o carregamento das tabelas de fatos\n","pagamento_header, pagamento_rdd = processaRdd(spark, pathPagamento)\n","negociacao_header, negociacao_rdd = processaRdd(spark, pathNegociacao)\n","\n","#Checando o resultado\n","display(equipe_header)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["['equipePK',\n"," 'equipeNome',\n"," 'filialNome',\n"," 'filialCidade',\n"," 'filialEstadoNome',\n"," 'filialEstadoSigla',\n"," 'filialRegiaoNome',\n"," 'filialRegiaoSigla',\n"," 'filialPaisNome',\n"," 'filialPaisSigla']"]},"metadata":{}}]},{"cell_type":"markdown","source":["**Dica 1 para o exercício**: Crie uma função para executar este procedimento repetidas vezes. Utilize o esqueleto a seguir como base.\n","```python\n","def processaRdd(spark, path):\n","  ...\n","  return header, rddCsv\n","```\n","**Dica 2**: Se tiver dificuldades em criar a função, replique os comandos descritos para o carregamento da tabela de dimensão data para todas as tabelas restantes."],"metadata":{"id":"It9_eETEFQxh"}},{"cell_type":"markdown","metadata":{"id":"Kugu7q5SY_qu"},"source":["### **Exercício 2**\n","\n","Selecione as seguintes colunas do RDD `cliente`: primeira, segunda, terceira e sexta. Exiba as 5 primeiras linhas resultantes. Consulte `cliente_header` caso necessário. "]},{"cell_type":"code","metadata":{"id":"nMlSfkzkU4rg","colab":{"base_uri":"https://localhost:8080/","height":284},"executionInfo":{"status":"ok","timestamp":1666902079875,"user_tz":180,"elapsed":412,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"41b77f61-692e-41e9-cfc0-887917ab5615"},"source":["# Resposta do exercício\n","\n","# Verificando quais colunas estão presentes no RDD cliente\n","display(cliente_header)\n","\n","# Selecionando as colunas solicitadas\n","cliente_rdd.map(lambda x: (x[0], x[1], x[2], x[5])).take(5)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["['clientePK',\n"," 'clienteNomeFantasia',\n"," 'clienteSetor',\n"," 'clienteCidade',\n"," 'clienteEstadoNome',\n"," 'clienteEstadoSigla',\n"," 'clienteRegiaoNome',\n"," 'clienteRegiaoSigla',\n"," 'clientePaisNome',\n"," 'clientePaisSigla']"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[('1', 'VIA FOOD', 'BEBIDAS E ALIMENTOS', 'SP'),\n"," ('2', 'VIA PIZZA', 'BEBIDAS E ALIMENTOS', 'SP'),\n"," ('3', 'VIA JAPA', 'BEBIDAS E ALIMENTOS', 'SP'),\n"," ('4', 'VIA VEG', 'BEBIDAS E ALIMENTOS', 'SP'),\n"," ('5', 'VIA DRINK', 'BEBIDAS E ALIMENTOS', 'SP')]"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"Jb07Xgblptuf"},"source":["**Dica para o exercício:** método ***map()***\n","\n","O método `map()` pode ser utilizado para selecionar colunas. Veja o exemplo abaixo:"]},{"cell_type":"code","metadata":{"id":"Sq268iE9450V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666902093030,"user_tz":180,"elapsed":258,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"1df42c99-06e4-4565-afd3-6a704c856e13"},"source":["#selecionando as seguintes colunas do RDD \"funcionario\":  segunda, terceira, décima\n","funcionario_rdd \\\n","  .map(lambda x: (x[1], x[2], x[9])) \\\n","  .take(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('M-1', 'ALINE ALMEIDA', 'SAO PAULO'),\n"," ('M-2', 'ARAO ALVES', 'SAO PAULO'),\n"," ('M-3', 'ARON ANDRADE', 'SAO PAULO'),\n"," ('M-4', 'ADA BARBOSA', 'SAO PAULO'),\n"," ('M-5', 'ABADE BATISTA', 'SAO PAULO')]"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"6W4su6k1aGkZ"},"source":["### **Exercício 3**\n","\n","Recupere os clientes que moram no estado de Minas Gerais."]},{"cell_type":"code","metadata":{"id":"pO9fBhbGU6v2","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1666902244732,"user_tz":180,"elapsed":308,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"df936df4-404e-4746-8ecb-b590589ba431"},"source":["# Resposta do exercício\n","\n","# Verificando quais colunas estão presentes no RDD cliente\n","display(cliente_header)\n","\n","# Mostrando os 5 primeiros elementos do RDD que contém os clientes que moram no estado de Minas Gerais\n","cliente_rdd.filter(lambda x: x[5] == \"MG\").take(5)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["['clientePK',\n"," 'clienteNomeFantasia',\n"," 'clienteSetor',\n"," 'clienteCidade',\n"," 'clienteEstadoNome',\n"," 'clienteEstadoSigla',\n"," 'clienteRegiaoNome',\n"," 'clienteRegiaoSigla',\n"," 'clientePaisNome',\n"," 'clientePaisSigla']"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[('10',\n","  'VIA LIFE',\n","  'SAUDE',\n","  'BELO HORIZONTE',\n","  'MINAS GERAIS',\n","  'MG',\n","  'SUDESTE',\n","  'SE',\n","  'BRASIL',\n","  'BR'),\n"," ('11',\n","  'VIA MED',\n","  'SAUDE',\n","  'UBERLANDIA',\n","  'MINAS GERAIS',\n","  'MG',\n","  'SUDESTE',\n","  'SE',\n","  'BRASIL',\n","  'BR'),\n"," ('30',\n","  'SR. HAPPY HOUR',\n","  'BEBIDAS E ALIMENTOS',\n","  'BELO HORIZONTE',\n","  'MINAS GERAIS',\n","  'MG',\n","  'SUDESTE',\n","  'SE',\n","  'BRASIL',\n","  'BR'),\n"," ('31',\n","  'SR. LIFE',\n","  'SAUDE',\n","  'UBERLANDIA',\n","  'MINAS GERAIS',\n","  'MG',\n","  'SUDESTE',\n","  'SE',\n","  'BRASIL',\n","  'BR'),\n"," ('50',\n","  'SR. FRIENDS',\n","  'BEBIDAS E ALIMENTOS',\n","  'BELO HORIZONTE',\n","  'MINAS GERAIS',\n","  'MG',\n","  'SUDESTE',\n","  'SE',\n","  'BRASIL',\n","  'BR')]"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"5Ng3iGSNsnNH"},"source":["**Dica para o exercício**: Método ***filter()***\n","\n","O método `filter()` pode ser utilizado para filtrar valores de acordo com  critérios de seleção. No exemplo a seguir, o método `filter()` é utilizado para filtrar os funcionários que **não** são do estado de `'SAO PAULO'`."]},{"cell_type":"code","source":["cliente_rdd.filter(lambda x: x[5] != \"SP\").take(7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9yGqmXzH4zp","executionInfo":{"status":"ok","timestamp":1666902433403,"user_tz":180,"elapsed":269,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"c5009283-2cea-4e52-cca0-635161824232"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('7',\n","  'VIA PASTA',\n","  'BEBIDAS E ALIMENTOS',\n","  'RIO DE JANEIRO',\n","  'RIO DE JANEIRO',\n","  'RJ',\n","  'SUDESTE',\n","  'SE',\n","  'BRASIL',\n","  'BR'),\n"," ('8',\n","  'VIA FRIENDS',\n","  'BEBIDAS E ALIMENTOS',\n","  'RIO DE JANEIRO',\n","  'RIO DE JANEIRO',\n","  'RJ',\n","  'SUDESTE',\n","  'SE',\n","  'BRASIL',\n","  'BR'),\n"," ('9',\n","  'VIA HAPPY HOUR',\n","  'BEBIDAS E ALIMENTOS',\n","  'RIO DE JANEIRO',\n","  'RIO DE JANEIRO',\n","  'RJ',\n","  'SUDESTE',\n","  'SE',\n","  'BRASIL',\n","  'BR'),\n"," ('10',\n","  'VIA LIFE',\n","  'SAUDE',\n","  'BELO HORIZONTE',\n","  'MINAS GERAIS',\n","  'MG',\n","  'SUDESTE',\n","  'SE',\n","  'BRASIL',\n","  'BR'),\n"," ('11',\n","  'VIA MED',\n","  'SAUDE',\n","  'UBERLANDIA',\n","  'MINAS GERAIS',\n","  'MG',\n","  'SUDESTE',\n","  'SE',\n","  'BRASIL',\n","  'BR'),\n"," ('12',\n","  'VIA PREVENT',\n","  'SAUDE',\n","  'SALVADOR',\n","  'CEARA',\n","  'CE',\n","  'NORDESTE',\n","  'NE',\n","  'BRASIL',\n","  'BR'),\n"," ('13',\n","  'VIA SENIOR',\n","  'SAUDE',\n","  'RECIFE',\n","  'PERNAMBUCO',\n","  'PE',\n","  'NORDESTE',\n","  'NE',\n","  'BRASIL',\n","  'BR')]"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"2C8HjkEpPHyw"},"source":["### **Exercício 4**\n","\n","Realize a junção da tabela cliente com a tabela negociacao, considerando a integridade referencial definida em termos de clientePK (ou seja, `cliente.clientePK = negociacao.clientePK`). "]},{"cell_type":"code","metadata":{"id":"iQr24liGU7z5","colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"status":"ok","timestamp":1666902532758,"user_tz":180,"elapsed":692,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"2eeeaacf-6317-4b5a-a549-9f58183ea071"},"source":["# Resposta do exercício\n","\n","# Verificando quais colunas estão presentes no RDD cliente\n","display(cliente_header)\n","\n","# Verificando quais colunas estão presentes no RDD negociacao\n","display(negociacao_header)\n","\n","# Realizando a junção dos RDDs cliente e negociacao\n","cliente_rdd.join(negociacao_rdd).take(5)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["['clientePK',\n"," 'clienteNomeFantasia',\n"," 'clienteSetor',\n"," 'clienteCidade',\n"," 'clienteEstadoNome',\n"," 'clienteEstadoSigla',\n"," 'clienteRegiaoNome',\n"," 'clienteRegiaoSigla',\n"," 'clientePaisNome',\n"," 'clientePaisSigla']"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["['equipePK', 'clientePK', 'dataPK', 'receita', 'quantidadeNegociacoes']"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[('4', ('VIA VEG', '4')),\n"," ('4', ('VIA VEG', '18')),\n"," ('4', ('VIA VEG', '36')),\n"," ('4', ('VIA VEG', '135')),\n"," ('4', ('VIA VEG', '142'))]"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"e4IYWDCguVhF"},"source":["**Dica para exercício:** Método ***join()***\n","\n","O método `join()` pode ser utilizado para juntar duas tabelas de acordo com a integridade referencial, ou seja, de acordo com a chave primária presente em uma primeira tabela e a chave secundária presente em uma segunda tabela.\n","\n","No exemplo a seguir, o método `join()` é utilizado para juntar dados da tabela de dimensão funcionario com dados da tabela de dimensão pagamento, utilizando a junção estrela definida em termos de `funcionario.funcPK = pagamento.funcPK`"]},{"cell_type":"code","metadata":{"id":"q4ub2lviuHat","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"ok","timestamp":1666901002307,"user_tz":180,"elapsed":6,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"914578df-eb00-4640-ef53-6415158a693a"},"source":["#listando os metadados de funcionário\n","display(funcionario_header)\n","\n","#criando um RDD temporário para funcionário, contendo apenas algumas colunas \n","funcionario_temp = funcionario_rdd \\\n","  .map(lambda x: (x[0], x[2], x[9]))\n","\n","#listando os 5 primeiros elementos de \"funcionario_temp\"\n","funcionario_temp \\\n","  .take(5)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["['funcPK',\n"," 'funcMatricula',\n"," 'funcNome',\n"," 'funcSexo',\n"," 'funcDataNascimento',\n"," 'funcDiaNascimento',\n"," 'funcMesNascimento',\n"," 'funcAnoNascimento',\n"," 'funcCidade',\n"," 'funcEstadoNome',\n"," 'funcEstadoSigla',\n"," 'funcRegiaoNome',\n"," 'funcRegiaoSigla',\n"," 'funcPaisNome',\n"," 'funcPaisSigla']"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[('1', 'ALINE ALMEIDA', 'SAO PAULO'),\n"," ('2', 'ARAO ALVES', 'SAO PAULO'),\n"," ('3', 'ARON ANDRADE', 'SAO PAULO'),\n"," ('4', 'ADA BARBOSA', 'SAO PAULO'),\n"," ('5', 'ABADE BATISTA', 'SAO PAULO')]"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"qTdpAtxIvJnv","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1666901002307,"user_tz":180,"elapsed":5,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"69443593-43a2-40c0-ab96-33dd7d0c0d50"},"source":["#listando os metadados de pagamento\n","display(pagamento_header)\n","\n","#criando um RDD temporário para pagamento, contendo apenas as colunas referentes à funcPK e às medidas numéricas\n","pagamento_temp = pagamento_rdd\\\n","  .map(lambda x: (x[0], x[4], x[1]))\n","\n","#listando os 5 primeiros elementos de \"pagamento_temp\" para o funcionário com funcPK = 5\n","def filterPagamentoFuncionario(func):\n","  return True if func[0] == '4' else False\n","pagamento_temp.filter(filterPagamentoFuncionario).take(5)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["['funcPK', 'equipePK', 'dataPK', 'cargoPK', 'salario', 'quantidadeLancamentos']"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[('4', '10498.14', '5'),\n"," ('4', '10498.14', '5'),\n"," ('4', '10498.14', '5'),\n"," ('4', '10498.14', '5'),\n"," ('4', '10498.14', '5')]"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"kwIve0rguezx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666901002717,"user_tz":180,"elapsed":414,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"45a5fa70-d7eb-44e1-f9c5-9858c14dd2f4"},"source":["#realizando a junção de funcionario_temp com pagamento_temp, para o funcionário com funcPK igual a 5\n","#note que a juncao é feita considerando a igualdade na primeira coluna\n","#note também que somente os valores da segunda coluna de funcionario e de pagamento são retornados \n","funcionario_temp \\\n","  .join(pagamento_temp) \\\n","  .take(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('4', ('ADA BARBOSA', '10498.14')),\n"," ('4', ('ADA BARBOSA', '10498.14')),\n"," ('4', ('ADA BARBOSA', '10498.14')),\n"," ('4', ('ADA BARBOSA', '10498.14')),\n"," ('4', ('ADA BARBOSA', '10498.14'))]"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"zOm-dvwzU73U"},"source":["### **Exercício 5** \n","\n","Liste a quantidade de clientes por região. Ordene o resultado pelo nome da região em ordem crescente."]},{"cell_type":"code","source":["# Resposta do exercício\n","\n","# Verificando quais colunas estão presentes no RDD cliente\n","display(cliente_header)\n","\n","# Calculando a quantidade de clientes por região e ordenando o resultado\n","cliente_rdd.map(lambda x: (x[6], 1)) \\\n","  .reduceByKey(lambda x, y: x + y) \\\n","  .sortBy(lambda element: element[0]) \\\n","  .collect()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"K_z4vMhyW5yK","executionInfo":{"status":"ok","timestamp":1666902641144,"user_tz":180,"elapsed":511,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"4400e1d7-ec56-4d80-a4ae-b00f39b85874"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["['clientePK',\n"," 'clienteNomeFantasia',\n"," 'clienteSetor',\n"," 'clienteCidade',\n"," 'clienteEstadoNome',\n"," 'clienteEstadoSigla',\n"," 'clienteRegiaoNome',\n"," 'clienteRegiaoSigla',\n"," 'clientePaisNome',\n"," 'clientePaisSigla']"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[('CENTRO-OESTE', 10),\n"," ('NORDESTE', 30),\n"," ('NORTE', 10),\n"," ('SUDESTE', 130),\n"," ('SUL', 30)]"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","metadata":{"id":"ul9bgXCoAxFH"},"source":["**Dica para o exercício**: Método ***reduceByKey()***\n","\n","O método `reduceByKey()` pode ser utilizado para calcular valores agregados para cada valor de chave presente em uma coluna. \n","\n","No exemplo a seguir, é listada a quantidade de funcionários por estado.\n","\n","Para responder a essa consulta, é necessário utilizar os dados de `funcionario_rdd`, usando a coluna `funcEstadoNome` e contando quantas vezes o mesmo nome de estado aparece. São executados os seguintes passos:\n","\n","- Utilização do método `map()` para selecionar a coluna desejada `funcEstadoNome`, que é a décima coluna de `funcionario_rdd`, e para criar pares chave-valor da seguinte forma: a chave corresponde à coluna `funcEstadoNome` e o valor corresponde a 1.\n","- Utilização do método `reduceByKey()` para calcular, para cada chave a quantidade de vezes que ela aparece.\n","- Utilização do método `collect()` para exibir os pares chave-valor obtidos."]},{"cell_type":"code","metadata":{"id":"6QS8GB9JRDQg","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"ok","timestamp":1666902738545,"user_tz":180,"elapsed":275,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"9d53f8a5-8d33-46dd-98c3-5c8da9c7f93c"},"source":["# Verificando quais colunas estão presentes no RDD funcionario\n","display(funcionario_header)\n","\n","# Executando os passos necessários para responder à consulta\n","funcionario_rdd \\\n","  .map(lambda x: (x[9], 1)) \\\n","  .reduceByKey(lambda x, y: x + y) \\\n","  .collect()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["['funcPK',\n"," 'funcMatricula',\n"," 'funcNome',\n"," 'funcSexo',\n"," 'funcDataNascimento',\n"," 'funcDiaNascimento',\n"," 'funcMesNascimento',\n"," 'funcAnoNascimento',\n"," 'funcCidade',\n"," 'funcEstadoNome',\n"," 'funcEstadoSigla',\n"," 'funcRegiaoNome',\n"," 'funcRegiaoSigla',\n"," 'funcPaisNome',\n"," 'funcPaisSigla']"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[('MINAS GERAIS', 28),\n"," ('PARANA', 28),\n"," ('PERNAMBUCO', 21),\n"," ('SAO PAULO', 95),\n"," ('RIO DE JANEIRO', 28)]"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"QFmWox4teixh"},"source":["### **Exercício 6** \n","\n","Qual foi o maior e o menor salário pago em 2019?\n"]},{"cell_type":"markdown","source":["\n","**Dica para o exercício**: Para responder a essa consulta, é necessário utilizar os dados de pagamento_rdd, usando a coluna salario e aplicando o método min() e max(), considerando a seguinte sequência de passos.\n","\n","- Utilização do método `map()` para transformar o tipo de dados da coluna salario em um número de ponto flutuante (ou seja, float)\n","\n","- Utilização do método `min()` para descobrir o menor salário.\n","\n","- Utilização do método `max()` para descobrir o maior salário."],"metadata":{"id":"4EoEZu2GXpmQ"}},{"cell_type":"code","metadata":{"id":"kz0gtXCWVAzo","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1666902927245,"user_tz":180,"elapsed":709,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"38884101-2f93-4c9c-f8e2-6c1d0b706feb"},"source":["# Resposta do exercício\n","\n","# Verificando quais colunas estão presentes no RDD pagamento\n","display(pagamento_header)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["['funcPK', 'equipePK', 'dataPK', 'cargoPK', 'salario', 'quantidadeLancamentos']"]},"metadata":{}}]},{"cell_type":"code","source":["# Obtendo o menor salário\n","pagamento_rdd.map(lambda x: float(x[4])).min()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Ghwy5ZzX3FA","executionInfo":{"status":"ok","timestamp":1666902930120,"user_tz":180,"elapsed":256,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"26b2e656-259a-4a6f-cf53-52774085bb38"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1501.57"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["# Obtendo o maior salário\n","pagamento_rdd.map(lambda x: float(x[4])).max()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CV3XWSZ2X-Yk","executionInfo":{"status":"ok","timestamp":1666902932236,"user_tz":180,"elapsed":284,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"a51f8ac4-a62c-49ce-c3e2-3f1128bcab6e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["47140.17"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","metadata":{"id":"Y6wTUtmqrvVg"},"source":["### **Exercício 7** \n","\n","Qual a idade média dos funcionários? Para fazer este exercício, não precisa considerar a idade exata, ou seja, não é necessário considerar o dia no qual o funcionário nasceu. Considere apenas o ano de nascimento do funcionário.  "]},{"cell_type":"markdown","metadata":{"id":"3djTT4Bqv3xZ"},"source":["**Exercício 7a** Resolva o exercício utilizando o método *mean()*."]},{"cell_type":"markdown","source":["A seguinte sequência de passos deve ser realizada:\n","\n","- Utilização do método `map()` para obter os anos de nascimento dos funcionários.\n","- Utilização do método `map()` para calcular a idade do funcionário, considerando o ano atual de 2020 e o ano no qual o funcionário nasceu. \n","- Utilização do método `mean()` para gerar o resultado final."],"metadata":{"id":"0cJzAJBwYrVw"}},{"cell_type":"code","metadata":{"id":"A1FX7PM6VBqG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666902972226,"user_tz":180,"elapsed":262,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"bb7cd883-dc46-4508-8d6a-fb931b5cb9b6"},"source":["# Resposta do exercício\n","\n","# Criando uma função que calcula a idade a partir do ano\n","def idadeApartirDeAno(ano):\n","  anoAtual = 2020\n","  return anoAtual - int(ano)\n","\n","# Calculando a idade média dos funcionários usando o método mean()\n","funcionario_rdd \\\n","  .map(lambda x: (x[7])) \\\n","  .map(lambda x: idadeApartirDeAno(x)) \\\n","  .mean()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["37.595"]},"metadata":{},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"loLsid3QwfeW"},"source":["**Exercício 7b** Resolva o exercício **sem** usar o método *mean().*"]},{"cell_type":"markdown","source":["A seguinte sequência de passos deve ser realizada:\n","\n","- Utilização do método `map()` para obter os anos de nascimento dos funcionários.\n","- Utilização do método `map()` para calcular a idade do funcionário, considerando o ano atual de 2020 e o ano no qual o funcionário nasceu. \n","- Utilização do método `map()` para gerar pares chave-valor, de forma que a chave seja a idade do funcionário e o valor seja 1.\n","- Utilização do método `reduceByKey()` reduzindo pelas chaves e somando as idades e as quantidades de linhas.\n","- Utilização do método `mapValues()` para mapear os valores e para dividir as somas das idades pelas quantidades de linhas.\n","- Utilização do método `map()` para mapear a idade média dos funcionários."],"metadata":{"id":"4JGT7uSAY1KK"}},{"cell_type":"code","metadata":{"id":"cOSOfoXUVCNn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666903006465,"user_tz":180,"elapsed":308,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"58f64d51-7a69-48b3-c516-49e2af043469"},"source":["# Resposta do exercício\n","\n","# Criando uma função que calcula idade a partir de ano\n","def idadeApartirDeAno(ano):\n","  anoAtual = 2020\n","  return anoAtual - int(ano)\n","\n","# Calculando a idade média dos funcionários usando o método mean()\n","funcionario_rdd \\\n","  .map(lambda x: (x[7])) \\\n","  .map(lambda x: idadeApartirDeAno(x)) \\\n","  .map(lambda x: (1, (x, 1))) \\\n","  .reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1])) \\\n","  .mapValues(lambda x: x[0]/x[1]) \\\n","  .map(lambda x: x[1]) \\\n","  .collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[37.595]"]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"ED2laZHr4oPO"},"source":["### **Exercício 8**\n","\n","Liste a quantidade de vezes que cada palavra individual aparece nos nomes de cidades que os funcionários moram. Por exemplo, na cidade de SAO JOSE DO RIO PRETO, existem 5 palavras individuais. Ordene o resultado de forma que as palavras individuais que mais se repetem sejam mostradas primeiro. \n"]},{"cell_type":"code","source":["# Resposta do exercício\n","\n","# Verificando quais colunas estão presentes no RDD pagamento\n","display(funcionario_header)\n","\n","# Calculando a quantidade de vezes que cada palavra individual aparece\n","funcionario_rdd.map(lambda x: x[8]). \\\n","    flatMap(lambda line: line.split(\" \")). \\\n","    map(lambda word: (word, 1)). \\\n","    reduceByKey(lambda x, y: x + y). \\\n","    sortBy(lambda word_count: word_count[1], ascending=False). \\\n","    collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":961},"id":"tduOqi6yZTec","executionInfo":{"status":"ok","timestamp":1666903098547,"user_tz":180,"elapsed":882,"user":{"displayName":"Cristina Aguiar","userId":"02805498492766545440"}},"outputId":"9155b5ee-2f0e-4c47-c4b1-5bcdd7947519"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["['funcPK',\n"," 'funcMatricula',\n"," 'funcNome',\n"," 'funcSexo',\n"," 'funcDataNascimento',\n"," 'funcDiaNascimento',\n"," 'funcMesNascimento',\n"," 'funcAnoNascimento',\n"," 'funcCidade',\n"," 'funcEstadoNome',\n"," 'funcEstadoSigla',\n"," 'funcRegiaoNome',\n"," 'funcRegiaoSigla',\n"," 'funcPaisNome',\n"," 'funcPaisSigla']"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[('SAO', 24),\n"," ('PRETO', 23),\n"," ('RECIFE', 21),\n"," ('RIO', 15),\n"," ('CAMPINAS', 8),\n"," ('RIBEIRAO', 8),\n"," ('ILHA', 8),\n"," ('JOSE', 8),\n"," ('PAULO', 8),\n"," ('SANTOS', 8),\n"," ('SANTO', 8),\n"," ('ANDRE', 8),\n"," ('PIRACICABA', 8),\n"," ('CARLOS', 8),\n"," ('BELA', 8),\n"," ('DO', 8),\n"," ('OSASCO', 8),\n"," ('ARARAQUARA', 8),\n"," ('BARUERI', 7),\n"," ('DE', 7),\n"," ('REDONDA', 7),\n"," ('ANGRA', 7),\n"," ('DOS', 7),\n"," ('PRAIA', 7),\n"," ('SECA', 7),\n"," ('HORIZONTE', 7),\n"," ('ARAGUARI', 7),\n"," ('MONTE', 7),\n"," ('CURITIBA', 7),\n"," ('GUARATUBA', 7),\n"," ('MORRETES', 7),\n"," ('JANEIRO', 7),\n"," ('VOLTA', 7),\n"," ('REIS', 7),\n"," ('BELO', 7),\n"," ('OURO', 7),\n"," ('VERDE', 7),\n"," ('LONDRINA', 7)]"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","source":["### **Exercício 9** \n","\n","Considere o código Python a seguir, o qual tem como objetivo contar quantas\n","vezes uma determinada palavra aparece em um arquivo texto com 4 linhas de log.\n","\n","```python\n","error_lines = [\"\"\"(2021-11-01 06:58:43) ERROR - Event with job id 1abc Failed,\n","                  (2021-11-01 06:58:47) ERROR - Event with job id 2abc Failed,\n","                  (2021-11-01 06:58:50) ERROR - Event with job id 3abc Failed,\n","                  (2021-11-01 06:59:43) INFO - Number of table lines is 102345.\"\"\"]\n","\n","output = spark.\\\n","parallelize(error_lines).\\\n","flatMap(lambda element: element.split(\" \")).\\\n","filter(lambda element: True if element == 'ERROR' else False).\\\n","count()\n","```\n","Explique qual é a função dos métodos *flatMap(), filter() e count(). Explique também qual o resultado da variável `output`.\n"],"metadata":{"id":"_ynnKV96RF7Z"}},{"cell_type":"markdown","source":["**Resposta do Exercício:**\n","\n","**Método `flatMap()`**: Aplica a função lambda para todos os elementos presentes no RDD gerado pelo método `parallelize()` e nivela os resultados. Da forma como está especificada,a função lambda realiza a separação das palavras por espaço em branco usando o método `split()` nativo do Python.\n","\n","**Método `filter()`:** Aplica a função booleana lambda sobre todos os elementos do RDD e retorna apenas os elementos que são verdadeiros baseados em uma condição. Da forma como está especificada, a função lambda retorna todas as palavras que são iguais à string \"`ERROR`\".\n","\n","**Método `count()`:** Retorna o número de elementos do RDD. \n","\n","**Resultado da variável `output`:** Da forma como está especificado, o método `count()` retorna quantas vezes a palavra “ERROR” aparece. O valor da variável `output` é 3, pois considerando o arquivo de log representado por `error_lines` e a forma como está especificado o código Python, a palavra \"`ERROR`\" aparece 3 vezes."],"metadata":{"id":"lfwznS3laGo-"}},{"cell_type":"markdown","metadata":{"id":"Wo5CVe25TX8o"},"source":["### **Exercício 10**\n","\n","Considere a figura a seguir, a qual representa um cluster de computadores que segue\n","a arquitetura do sistema de arquivos distribuídos HDFS (*Hadoop Distributed File System*).\n","Ao lado de cada quadrado, existe uma numeração que representa o componente dentro\n","daquele quadrado. Responda às questões a seguir, utilizando como base essa numeração.\n","\n"]},{"cell_type":"markdown","source":["<br>\n","\n","<p align=\"center\"><img src=\"https://raw.githubusercontent.com/kenjitakatuzi/MBA-ICMC-2022/main/images/CLUSTER.png\" width=\"500\" height=\"300\"></p>\n","<!-- <p align=\"center\">Figura 1 - Representação de um cluster de computadores que segue a arquitetura do HDFS. </p> -->\n","\n","<br>"],"metadata":{"id":"aILuDaa6YjUX"}},{"cell_type":"markdown","source":["**Resposta do Exercício:**\n","\n","(1) Componente 1\n","\n","(2) Componentes 2, 3 e 4\n","\n","(3) Componente 5\n","\n","(4) Componentes 2, 3 e 4\n","\n","(5) Componentes 1 e 5\n","\n","(6) Componentes 2, 3 e 4"],"metadata":{"id":"t4jWwTYRbHxx"}},{"cell_type":"markdown","source":["### **Exercício 11**\n","\n","Transformações são operações que transformam um RDD (Resilient and Distributed Datasets) em outro RDD. No Spark, as transformações não são executadas imediatamente sobre os dados do RDD. Elas são anexadas ao grafo acíclico direcionado de transformações, o qual é executado apenas quando uma ação sobre o RDD em questão for solicitada. Essa característica é conhecida como lazy-evaluation.\n","\n","Como resultado, operações podem ser executadas em conjunto, possibilitando otimizações. Por exemplo, os métodos `map()` e `reduceByKey()` são transformações, e eles somente são executados quando ocorrer uma ação, como quando o método collect() for chamado. Portanto, `map()`, `reduceByKey()` e `collect()` podem ser executados em conjunto.\n","\n","No exemplo do contador de palavras, comumente utiliza-se o que é conhecido como side-map reducer, indicando que internamente o Spark usa uma estrutura de HashMap e faz o método de `reduceByKey()` localmente antes de enviar o resultado para a etapa de reducing propriamente dita. Isso é ilustrado por meio da seta azul na figura a seguir.\n","\n","Por outro lado, o framework Hadoop não provê operações com a característica de *lazy-evaluation*. Portanto, operações não são executadas em conjunto. Refaça a figura a seguir de forma que o exemplo do contador de palavras não considere essa característica, ou seja, que o contador de palavras não considere a característica de *lazy-evaluation*.\n","\n","**Dica para o exercício:** Ao invés de refazer a figura, é possível discutir as alterações que precisam ser feitas."],"metadata":{"id":"kuY5OZ3XQYMJ"}},{"cell_type":"markdown","source":["<br>\n","\n","<p align=\"center\"><img src=\"https://raw.githubusercontent.com/kenjitakatuzi/MBA-ICMC-2022/main/images/FIGURA1.jpeg\" width=\"600\" height=\"300\"></p>\n","<!-- <p align=\"center\">Figura 2 - Exemplo de contador de palavras.</p> -->\n","\n","<br>"],"metadata":{"id":"WwCrgjuAQ9Mz"}},{"cell_type":"markdown","source":["\n","\n","**Resposta do exercício:**"],"metadata":{"id":"D7EJc8MJM20d"}},{"cell_type":"markdown","source":["<br>\n","\n","<p align=\"center\"><img src=\"https://raw.githubusercontent.com/kenjitakatuzi/MBA-ICMC-2022/main/images/FIGURA2.jpeg\" width=\"600\" height=\"300\"></p>\n","<!-- <p align=\"center\">Figura 1. Exemplo de contador de palavras. </p> -->\n","\n","<br>"],"metadata":{"id":"vSPPTTmORSgI"}}]}