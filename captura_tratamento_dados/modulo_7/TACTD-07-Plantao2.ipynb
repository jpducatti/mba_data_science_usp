{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBA em Ciência de Dados\n",
    "## Técnicas Avançadas de Captura e Tratamento de Dados\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo VII - Dados não estruturados: sinais e imagens</span>\n",
    "\n",
    "### <span style=\"color:darkred\">Exercícios</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "#### <span style=\"color:red\">Recomenda-se fortemente que os exercícios sejam feitos sem consultar as respostas antecipadamente.</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando as bibliotecas necessárias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1)\n",
    "\n",
    "Quando comparamos imagens e sinais e suas características, o que devemos considerar a priori?\n",
    "\n",
    "(a) Sinais possuem valores independente e identicamente distribuídos, enquanto Imagens possuem pixels organizados de forma espacial<br>\n",
    "(b) Sinais possuem valores codificados em 16 bits, enquanto imagens possuem valores codificados em 8 bits<br>\n",
    "(c) Sinais possuem valores com dependência sequencial, enquanto imagens não possuem padrão de dependência<br>\n",
    "(d) Sinais possuem valores com dependência sequencial, enquanto Imagens possuem dependência espacial de seus valores<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2)\n",
    "\n",
    "Sejam sinais representados por 32 bits (int32) e imagens representadas por 16 bits sem sinal (uint16). Quantos valores distintos é possível representar em cada um desses dados?\n",
    "\n",
    "(a) Sinais: 4,29 Bilhões; Imagens 32,76 Mil<br>\n",
    "(b) Sinais: 4,29 Bilhões; Imagens 65,53 Mil<br>\n",
    "(c) Sinais: 2,14 Bilhões; Imagens 32,76 Mil<br>\n",
    "(d) Sinais: 2,14 Bilhões; Imagens 65,53 Mil<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3)\n",
    "\n",
    "Carregue os dados do arquivo `sinais2.csv` utilizando\n",
    "\n",
    "`signals = np.genfromtxt(arquivo, delimiter=',').astype(np.float32)`.\n",
    "\n",
    "O array resultante possui um sinal por linha, i.e. `sinal[i]`\n",
    "\n",
    "Utilizando os sinais carregados utilize a `np.fft.fft()` para obter a Transformada de Fourier dos sinais. Depois, considerando apenas frequências até 50, calcule quais são as 4 frequências de maior valor de magnitude (obtido pelo `np.abs()`). Aqui não queremos os valores da magnitude, mas a quais frequências (índices) elas se referem. Para complementar a análise, plote as magnitudes das transformadas até a frequência 50.\n",
    "\n",
    "Analisando as frequências de maior magnitude temos as frequências que mais caracterizam o sinal. Considerando as 4 frequências computadas anteriormente, podemos dividir os sinais em categorias distintas. Nesse sentido, qual análise abaixo está correta?\n",
    "\n",
    "(a) O sinal 4 possui frequências inferiores quando comparado com os demais, indicando que o sinal 4 é provavalmente  dependente sequencialmente, enquanto os demais são i.i.d.; assim podemos dividí-los em duas categorias: sinal 4 e sinais 0, 1, 2 e 3.<br>\n",
    "(b) O sinal 3 possui frequências mais significativas 20 Hz ou superior, indicando que é um sinal com maior qualidade de aquisição, e assim podemos categorizar em: sinal 3, e sinais 0, 1, 2 e 4.<br>\n",
    "(c) Todas as frequências estão abaixo de 50 Hz, sendo assim podemos dizer que os sinais são todos similares, sendo impossível dividí-los em categorias.<br>\n",
    "(d) O sinal 3 possui frequências mais significativas 20 Hz ou superior, possuindo transições mais rápidas de valores do que os outros com frequências caracerísticas menores do que 12Hz; e assim podemos categorizar em: sinal 3, e sinais 0, 1, 2 e 4.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4)\n",
    " \n",
    "Considerando os mesmos sinais carregados, compute as características: entropia da energia (com 10 blocos), taxa de cruzamentos por zero, entropia espectral (com 10 blocos), formando um vetor com 3 características para cada sinal.\n",
    "\n",
    "Após isso, compute a matriz de distâncias entre os sinais considerando a distância L1, i.e., a soma dos valores absolutos das diferenças entre dois vetores $A$ e $B$:\n",
    "\n",
    "$$\\sum_i |A_i - B_i|$$\n",
    "\n",
    "Da matriz, que indica a dissimilaridade entre pares de sinais, aplique uma soma na direção do eixo 0 (axis=0) e depois arredonde para inteiro `np.round(,0)`. Quais valores foram obtidos para cada sinal?\n",
    "\n",
    "(a) Sinais 0, 1, 2 e 4, soma 2; Sinal 3, soma 6.<br>\n",
    "(b) Sinais 0 e 4, soma 3; Sinais 1 e 2, soma 2; Sinal 3, soma 6.<br>\n",
    "(c) Sinais 0, 1, e 2, soma 2; Sinal 3, soma 6; Sinal 4, soma 3.<br>\n",
    "(d) Sinais 0, 1, e 2, soma 1; Sinal 3, soma 3; Sinal 4, soma 6.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5)\n",
    "\n",
    "Carregue as seguintes imagens da base de dados flickr_map_training:\n",
    "\n",
    "`\n",
    "img1 = imageio.imread(\"dados/flickr_map_training/107.jpg\")\n",
    "img2 = imageio.imread(\"dados/flickr_map_training/101.jpg\")\n",
    "img3 = imageio.imread(\"dados/flickr_map_training/112.jpg\")\n",
    "img4 = imageio.imread(\"dados/flickr_map_training/303.jpg\")\n",
    "img5 = imageio.imread(\"dados/flickr_map_training/400.jpg\")`\n",
    "\n",
    "Implemente um descritor de cor que computa um histograma utilizando a composição dos canais RGB em um único canal utilizando a seguinte operação, sendo R, G e B as matrizes relativas a cada canal de cor:\n",
    "\n",
    "$$I = R\\cdot0.3 +G\\cdot0.59 +B\\cdot0.11$$\n",
    "\n",
    "Permita definir o número de bins do histograma por meio da sua função e, antes de retornar, normalize o histograma dividindo pela soma.\n",
    "\n",
    "Depois, calcule a distância entre img1 carregada e as outras imagens (2, 3, 4, 5) utilizando: 16 bins e 4 bins. Qual foram as duas imagens mais similares, da mais próxima para a mais distante, nos dois casos?\n",
    "\n",
    "(a) 16 bins: img2, img4 ; 4 bins: img2, img3<br>\n",
    "(a) 16 bins: img2, img3 ; 4 bins: img4, img3<br>\n",
    "(b) 16 bins: img2, img3 ; 4 bins: img2, img4<br>\n",
    "(d) 16 bins: img4, img2 ; 4 bins: img4, img3<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 6)\n",
    "\n",
    "Vamos repetir o procedimento da questão anterior, agora utilizando o descritor de texturas LBP visto em aula. Utilizaremos uma função que também realiza uma normalização dos valores máximos das imagens, bem como permite definir o raio, número de pontos e quantidade de bins para esse descritor, conforme abaixo.\n",
    "\n",
    "Calcule a distância L1 entre img1 carregada e as outras imagens utilizando o descritor LBP com os seguintes parâmetros:\n",
    "* número de pontos = 14\n",
    "* raio = 2\n",
    "* bins = 16\n",
    "\n",
    "Quais foram as três imagens mais similares, da mais próxima para a mais distante?\n",
    "\n",
    "(a) img3, img2, img5<br>\n",
    "(b) img2, img3, img4<br>\n",
    "(c) img3, img5, img2<br>\n",
    "(d) img5, img3, img2<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 7)\n",
    " \n",
    "No método Bag-of-Features quais das seguintes escolhas para o *framework* influenciam mais drasticamente a performance do método no caso de uso em imagens?\n",
    "\n",
    "(a) O tamanho do dicionário, a quantidade de cores nas imagens, a quantidade de classes do problema<br>\n",
    "(b) O tamanho do dicionário, o descritor base, o método utilizado para aprender o dicionário<br>\n",
    "(c) O descritor base e o número de componentes principais utilizados<br>\n",
    "(d) O tamanho do patch extraído da imagem, que deve ser compatível com a resolução das imagens<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 8)\n",
    "\n",
    "Execute o método Bag-of-Features estudado em aula, agora com os seguintes parâmetros:\n",
    "* tamanho do patch = (13, 13)\n",
    "* número de patches = 1000\n",
    "* principais componentes = 10\n",
    "* tamanho do dicionário = 50\n",
    "\n",
    "Utilize a imagem de consulta `flower.jpg` e recupere as 12 imagens mais similares utilizando o modelo BoF aprendido. Quantas imagens foram recuperadas pertencendo à mesma categoria da consulta?\n",
    "\n",
    "(a) 3<br>\n",
    "(b) 0<br>\n",
    "(c) 6<br>\n",
    "(d) 9<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar as imagens\n",
    "\n",
    "# dividr as imagens em patches\n",
    "\n",
    "# extrair as características dos patches\n",
    "#     treinar PCA sobre os patches\n",
    "#     usar o PCA sobre os patches\n",
    "\n",
    "# fazer agrupamento (usando kmédias)\n",
    "\n",
    "# para cada patch, vamos encontrar o centroid mais próximo (treino)\n",
    "# computa o histograma das imagens da base de treino\n",
    "\n",
    "# carrega imagem consulta\n",
    "# extrair patches, usar PCA\n",
    "# para cada patch, vamos encontrar o centroid mais próximo\n",
    "# computa o histograma\n",
    "\n",
    "# comparar consulta com base de treino\n",
    "# encontrar 12 mais similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar as imagens\n",
    "import glob\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "image_files = glob.glob('dados/flickr_map_training/*')\n",
    "images_train = []\n",
    "for image_file in image_files:\n",
    "    images_train.append(imageio.imread(image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividr as imagens em patches\n",
    "import sklearn.feature_extraction.image\n",
    "\n",
    "def extract_patches(image, patch_size, max_patches, random_state):\n",
    "    patches = sklearn.feature_extraction.image.extract_patches_2d(\n",
    "    image, patch_size=(patch_size, patch_size), max_patches=max_patches, random_state=random_state)\n",
    "    \n",
    "    return patches\n",
    "\n",
    "image_patches = []\n",
    "for image in images_train:\n",
    "    patches = extract_patches(image, patch_size=13, max_patches=1000, random_state=1)\n",
    "    image_patches.append(patches)\n",
    "    \n",
    "image_patches = np.array(image_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1000, 13, 13, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extrair as características dos patches\n",
    "#     treinar PCA sobre os patches\n",
    "\n",
    "import sklearn.decomposition\n",
    "\n",
    "image_patches_reshape = image_patches.reshape(image_patches.shape[0]*image_patches.shape[1], -1)\n",
    "pca = sklearn.decomposition.PCA(n_components=10)\n",
    "pca.fit(image_patches_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     usar o PCA sobre os patches\n",
    "patches_pcad = pca.transform(image_patches_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(init='random', n_clusters=50, n_init=3, random_state=1, verbose=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fazer agrupamento (usando kmédias)\n",
    "import sklearn.cluster\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=50, \n",
    "                      verbose=False, \n",
    "                      init='random',\n",
    "                      random_state=1, \n",
    "                      n_init=3)\n",
    "kmeans.fit(patches_pcad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_bof(image_i):\n",
    "    patches_i = extract_patches(image_i, patch_size=13, max_patches=1000, random_state=1)\n",
    "    patches_i = patches_i.reshape(patches_i.shape[0], -1)\n",
    "    patches_pcad_i = pca.transform(patches_i)\n",
    "    matching_centroids = kmeans.predict(patches_pcad_i)\n",
    "    hist, bins = np.histogram(matching_centroids, bins=50, range=(0, 50))\n",
    "    hist = hist.astype(np.float32) / hist.astype(np.float32).sum()\n",
    "    # plt.bar(bins[:-1], hist)\n",
    "    # plt.show()\n",
    "    return hist\n",
    "\n",
    "# para cada patch, vamos encontrar o centroid mais próximo (treino)\n",
    "# computa o histograma das imagens da base de treino\n",
    "train_hists = []\n",
    "for image_i in images_train:\n",
    "    train_hists.append(extract_bof(image_i))\n",
    "train_hists = np.array(train_hists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.003, 0.001, 0.025, 0.002, 0.012, 0.011, 0.009, 0.025, 0.004,\n",
       "       0.003, 0.004, 0.001, 0.003, 0.006, 0.   , 0.062, 0.019, 0.026,\n",
       "       0.001, 0.002, 0.001, 0.156, 0.083, 0.007, 0.008, 0.011, 0.002,\n",
       "       0.036, 0.116, 0.129, 0.011, 0.005, 0.006, 0.023, 0.008, 0.019,\n",
       "       0.   , 0.005, 0.004, 0.006, 0.001, 0.012, 0.002, 0.006, 0.006,\n",
       "       0.002, 0.006, 0.073, 0.014, 0.023], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carrega imagem consulta\n",
    "image_query = imageio.imread('dados/flickr_map_test/flower.jpg')\n",
    "\n",
    "# extrair patches, usar PCA\n",
    "# para cada patch, vamos encontrar o centroid mais próximo\n",
    "# computa o histograma\n",
    "query_bof = extract_bof(image_query)\n",
    "query_bof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparar consulta com base de treino\n",
    "# encontrar 12 mais similares\n",
    "distances = []\n",
    "for hist_i in train_hists:\n",
    "    distances.append(np.sum(np.sqrt((hist_i - query_bof)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_distances_idx = np.argsort(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dados/flickr_map_training/600.jpg',\n",
       "       'dados/flickr_map_training/309.jpg',\n",
       "       'dados/flickr_map_training/217.jpg',\n",
       "       'dados/flickr_map_training/607.jpg',\n",
       "       'dados/flickr_map_training/606.jpg',\n",
       "       'dados/flickr_map_training/405.jpg',\n",
       "       'dados/flickr_map_training/608.jpg',\n",
       "       'dados/flickr_map_training/602.jpg',\n",
       "       'dados/flickr_map_training/302.jpg',\n",
       "       'dados/flickr_map_training/603.jpg',\n",
       "       'dados/flickr_map_training/604.jpg',\n",
       "       'dados/flickr_map_training/609.jpg'], dtype='<U33')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(image_files)[sort_distances_idx][:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 9)\n",
    " \n",
    "Execute o método Bag-of-Features estudado em aula, agora com os seguintes parâmetros:\n",
    "* tamanho do patch = (13, 13)\n",
    "* número de patches = 1000\n",
    "* tamanho do dicionário = 50\n",
    "* descritor base = LBP com raio 3, 24 pontos e 16 bins\n",
    "\n",
    "Vamos usar a versão da função LBP que permite usar como parâmetros o número de pontos e raio.\n",
    "\n",
    "Utilize imagem de consulta `football.jpg` e recupere as 12 imagens mais similares utilizando o modelo BoF aprendido. Qual a proporção de imagens da mesma categoria da consulta?\n",
    "\n",
    "(a) 0<br>\n",
    "(b) 9<br>\n",
    "(c) 4<br>\n",
    "(d) 2<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar as imagens\n",
    "\n",
    "# dividr as imagens em patches\n",
    "image_patches = []\n",
    "for image in images_train:\n",
    "    patches = extract_patches(image, patch_size=13, max_patches=1000, random_state=1)\n",
    "    image_patches.append(patches)\n",
    "    \n",
    "image_patches = np.array(image_patches)\n",
    "image_patches = image_patches.reshape((image_patches.shape[0]*image_patches.shape[1],)+image_patches.shape[2:])\n",
    "\n",
    "# extrair as características dos patches\n",
    "\n",
    "\n",
    "# fazer agrupamento (usando kmédias)\n",
    "\n",
    "# para cada patch, vamos encontrar o centroid mais próximo (treino)\n",
    "# computa o histograma das imagens da base de treino\n",
    "\n",
    "# carrega imagem consulta\n",
    "# extrair patches, usar PCA\n",
    "# para cada patch, vamos encontrar o centroid mais próximo\n",
    "# computa o histograma\n",
    "\n",
    "# comparar consulta com base de treino\n",
    "# encontrar 12 mais similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27,  21,   0,   0,   1,   2,   0,   4,   2,   1,   0,   0,   5,\n",
       "         2,   4, 100])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage.feature\n",
    "\n",
    "def extract_lbp(patch):\n",
    "    patch_bw = patch[..., 0]*0.3 + patch[..., 1]*0.59 + patch[..., 2]*0.11\n",
    "    patch_bw = patch_bw.astype(np.uint8)\n",
    "    patch_lbp = skimage.feature.local_binary_pattern(patch_bw, P=24, R=3, method=\"uniform\")\n",
    "    patch_lbp = patch_lbp.reshape([-1,])\n",
    "    lbp_hist, _ = np.histogram(patch_lbp, bins=16, range=(0, 25))\n",
    "    return lbp_hist\n",
    "extract_lbp(image_patches[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_lbped = []\n",
    "for patch in image_patches:\n",
    "    patches_lbped.append(extract_lbp(patch))\n",
    "patches_lbped = np.array(patches_lbped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(init='random', n_clusters=50, n_init=3, random_state=1, verbose=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fazer agrupamento (usando kmédias)\n",
    "import sklearn.cluster\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=50, \n",
    "                      verbose=False, \n",
    "                      init='random',\n",
    "                      random_state=1, \n",
    "                      n_init=3)\n",
    "kmeans.fit(patches_lbped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bof(image_i):\n",
    "    patches_i = extract_patches(image_i, patch_size=13, max_patches=1000, random_state=1)\n",
    "    patches_lbped_i = []\n",
    "    for patch in patches_i:\n",
    "        patches_lbped_i.append(extract_lbp(patch))\n",
    "    matching_centroids = kmeans.predict(patches_lbped_i)\n",
    "    hist, bins = np.histogram(matching_centroids, bins=50, range=(0, 50))\n",
    "    hist = hist.astype(np.float32) / hist.astype(np.float32).sum()\n",
    "    # plt.bar(bins[:-1], hist)\n",
    "    # plt.show()\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hists = []\n",
    "for image_i in images_train:\n",
    "    train_hists.append(extract_bof(image_i))\n",
    "train_hists = np.array(train_hists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.067, 0.016, 0.02 , 0.035, 0.073, 0.013, 0.051, 0.012, 0.015,\n",
       "       0.018, 0.   , 0.002, 0.001, 0.055, 0.006, 0.02 , 0.002, 0.   ,\n",
       "       0.   , 0.036, 0.015, 0.02 , 0.02 , 0.02 , 0.025, 0.026, 0.032,\n",
       "       0.032, 0.022, 0.003, 0.   , 0.028, 0.006, 0.04 , 0.001, 0.076,\n",
       "       0.011, 0.009, 0.018, 0.015, 0.035, 0.013, 0.013, 0.007, 0.   ,\n",
       "       0.038, 0.032, 0.   , 0.001, 0.   ], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carrega imagem consulta\n",
    "image_query = imageio.imread('dados/flickr_map_test/football.jpg')\n",
    "\n",
    "# extrair patches, usar PCA\n",
    "# para cada patch, vamos encontrar o centroid mais próximo\n",
    "# computa o histograma\n",
    "query_bof = extract_bof(image_query)\n",
    "query_bof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for hist_i in train_hists:\n",
    "    distances.append(np.sum(np.sqrt((hist_i - query_bof)**2)))\n",
    "sort_distances_idx = np.argsort(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dados/flickr_map_training/301.jpg',\n",
       "       'dados/flickr_map_training/103.jpg',\n",
       "       'dados/flickr_map_training/104.jpg',\n",
       "       'dados/flickr_map_training/219.jpg',\n",
       "       'dados/flickr_map_training/304.jpg',\n",
       "       'dados/flickr_map_training/609.jpg',\n",
       "       'dados/flickr_map_training/110.jpg',\n",
       "       'dados/flickr_map_training/411.jpg',\n",
       "       'dados/flickr_map_training/215.jpg',\n",
       "       'dados/flickr_map_training/201.jpg',\n",
       "       'dados/flickr_map_training/106.jpg',\n",
       "       'dados/flickr_map_training/102.jpg'], dtype='<U33')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(image_files)[sort_distances_idx][:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 10)\n",
    " \n",
    "Execute o método Bag-of-Features para aprender features nas imagens da pasta `flickr_map_training` conforme código fornecido em aula, com os seguintes parâmetros:\n",
    "* tamanho do patch = (11, 11)\n",
    "* número de patches = 350\n",
    "* descritor base = PCA com 16 componentes\n",
    "* random_state = 1\n",
    "* para o KMeans use random_state=1 e n_init=3\n",
    "\n",
    "Vamos investigar a influência do tamanho do dicionário no modelo gerado com os seguintes valores: 10, 50, 100, 250 e 500. Utilize a imagem de teste `flickr_map_test\\flower.jpg` para recuperar as 16 imagens mais similares no conjunto de treinamento (sabendo que há 10 imagens dessa categoria no conjunto de treinamento). Calcule a revocação, ou seja, a razão entre o total de imagens de flores retornadas na busca das 16 mais similares e o número total de imagens de flores que deveriam ter sido retornadas (10).\n",
    "\n",
    "DICA: as imagens de flores tem nome iniciando com o número '6'.\n",
    "\n",
    "Quais tamanhos de dicionário resultam em maior revocação?\n",
    "\n",
    "(a) 50 e 100 <br>\n",
    "(b) 50<br>\n",
    "(c) 100<br>\n",
    "(d) 250 e 500<br>\n",
    "(e) 10 e 50<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
